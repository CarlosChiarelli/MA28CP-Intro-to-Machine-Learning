{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"05-bonus-column-transformer.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"sMhABmRcd9P8","colab_type":"text"},"source":["# L05 - Bonus Notebook: Working with Heterogenous Datasets\n","\n","- Instructor: Dalcimar Casanova (dalcimar@gmail.com)\n","- Course website: https://www.dalcimar.com/disciplinas/aprendizado-de-maquina\n","- Bibliography: based on lectures of Dr. Sebastian Raschka\n","- Course website: http://pages.stat.wisc.edu/~sraschka/teaching/"]},{"cell_type":"code","metadata":{"id":"qOOPGJ_Bd9P-","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7oU_uVZ6d9QD","colab_type":"text"},"source":["- Suppose you have a dataset that has both numerical and categorical features as follows: "]},{"cell_type":"code","metadata":{"id":"X3Kbw3Q3d9QE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"outputId":"e8d45c29-4be6-4e58-cb6c-d076b91ffac6","executionInfo":{"status":"ok","timestamp":1584549333104,"user_tz":180,"elapsed":33132,"user":{"displayName":"Dalcimar Casanova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZzFT0FCo6nTJjXLoCVlWF617XKFK9oco_RLrc-A=s64","userId":"01490701818826847808"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","df = pd.read_csv('/content/drive/My Drive/Disciplinas/Aprendizado de Máquina/Public/L05_preprocessing-and-sklearn/code/data/iris_mod.csv', index_col='Id')\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SepalLength[cm]</th>\n","      <th>SepalWidth[cm]</th>\n","      <th>PetalLength[cm]</th>\n","      <th>PetalWidth[cm]</th>\n","      <th>Color_IMadeThisUp</th>\n","      <th>Species</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>red</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>red</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>red</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>red</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>red</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    SepalLength[cm]  SepalWidth[cm]  ...  Color_IMadeThisUp      Species\n","Id                                   ...                                \n","1               5.1             3.5  ...                red  Iris-setosa\n","2               4.9             3.0  ...                red  Iris-setosa\n","3               4.7             3.2  ...                red  Iris-setosa\n","4               4.6             3.1  ...                red  Iris-setosa\n","5               5.0             3.6  ...                red  Iris-setosa\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"R0bGJtjtd9QM","colab_type":"text"},"source":["- As usual, we first tranform the class labels into an integer format:"]},{"cell_type":"code","metadata":{"id":"f3-Z4cMWd9QN","colab_type":"code","colab":{}},"source":["X = df.drop('Species', axis=1)\n","y = df['Species']\n","\n","label_dict = {'Iris-setosa': 0,\n","              'Iris-versicolor': 1,\n","              'Iris-virginica': 2}\n","\n","y = y.map(label_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"360yw19Cd9QR","colab_type":"text"},"source":["- Next, we are going to set up a `Pipeline` that performs certain preprocessing steps only on the numerical features:"]},{"cell_type":"code","metadata":{"id":"8PgrFSBwd9QT","colab_type":"code","colab":{}},"source":["numeric_features = ['SepalLength[cm]', 'SepalWidth[cm]', 'PetalLength[cm]', 'PetalWidth[cm]']\n","\n","numeric_transformer = Pipeline(steps=[\n","    ('scaler', StandardScaler()),\n","    ('feature_extraction', PCA(n_components=2))])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3VDjHy77d9Qa","colab_type":"text"},"source":["- Above, we weren't interested in performing these preprocessing steps on the categorical feature(s); instead, we apply **different** preprocessing steps to the categorical variable like so:"]},{"cell_type":"code","metadata":{"id":"-kBEpKr2d9Qc","colab_type":"code","colab":{}},"source":["categorical_features = ['Color_IMadeThisUp']\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder())])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NKR8HyCAd9Qi","colab_type":"text"},"source":["- Scikit-learn's `ColumnTransformer` now allows us to merge these 2 seperate preprocessing pipelines, which operate on different feature sets in our dataset:"]},{"cell_type":"code","metadata":{"id":"oIuD8aGzd9Qj","colab_type":"code","colab":{}},"source":["preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EW95FGEhd9Qn","colab_type":"text"},"source":["- As a result, we get a 5 dimensional feature array (design matrix) if we apply this preprocessor. What are these 5 columns?"]},{"cell_type":"code","metadata":{"id":"0wGw5E4hd9Qo","colab_type":"code","colab":{},"outputId":"59707edc-7241-45a7-8f58-2eec22632838"},"source":["temp = preprocessor.fit_transform(X)\n","temp.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 5)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"xlCqhIoEd9Qu","colab_type":"code","colab":{},"outputId":"c719c836-c895-408e-e592-e1d356eb4cc1"},"source":["temp[:5]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.26454173,  0.5057039 ,  0.        ,  1.        ,  0.        ],\n","       [-2.0864255 , -0.65540473,  0.        ,  1.        ,  0.        ],\n","       [-2.36795045, -0.31847731,  0.        ,  1.        ,  0.        ],\n","       [-2.30419716, -0.57536771,  0.        ,  1.        ,  0.        ],\n","       [-2.38877749,  0.6747674 ,  0.        ,  1.        ,  0.        ]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"2voK0DUMd9Qz","colab_type":"text"},"source":["- The preprocessor can now also be conveniently be used in a Scikit-learn pipeline as shown below:"]},{"cell_type":"code","metadata":{"id":"4bOWaaRWd9Q0","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                                    test_size=0.2,\n","                                                    random_state=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8mc842V5d9Q4","colab_type":"code","colab":{},"outputId":"46b8a29b-8b68-411e-de6e-67c7c8c434bd"},"source":["clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', KNeighborsClassifier(p=3))])\n","\n","\n","clf.fit(X_train, y_train)\n","print(f'Test accuracy: {clf.score(X_test, y_test)*100}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test accuracy: 100.0%\n"],"name":"stdout"}]}]}